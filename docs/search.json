[
  {
    "objectID": "EEG.html#setting-up-the-cap",
    "href": "EEG.html#setting-up-the-cap",
    "title": "EEG Setup",
    "section": "Setting up the Cap",
    "text": "Setting up the Cap\nThe neoprene cap should always be clear of any debris from past participants. The cap should also be stationed on the Styrofoam head while not in use.\nThe cap is made of a flexible material and it should fit most heads.\nStep 1: Prepare the headcap and electrodes\n\nInsert the bottom parts of the electrodes in the headcap holes.\n[Take Picture]!\n\nTake note of the placements on the NIC2 screen.\n\n\n\nStep 2: Put on the headcap\n\nPlace the headcap on he participants head\nFasten the headcap comfortably.\n\nMake sure Cz is the midpoint from ear to ear.\n\nMake sure the headcap is properly aligned.\n\n\n\n\n\n[Take Picture]!"
  },
  {
    "objectID": "EEG.html#filling-electrodes",
    "href": "EEG.html#filling-electrodes",
    "title": "EEG Setup",
    "section": "Filling electrodes",
    "text": "Filling electrodes\n\nFor each electrode, use the syringe to move hair away and expose the scalp.\n\nFill the syringe with gel and put enough gel in the electrode.\n\nWhen you think you have put enough, put more!\n\n\n\n\nMake sure to screw together top and bottom parts of the electrode.\n\n[Take Picture/Video]"
  },
  {
    "objectID": "EEG.html#validating-connection",
    "href": "EEG.html#validating-connection",
    "title": "EEG Setup",
    "section": "Validating Connection",
    "text": "Validating Connection\n\nClip the cables onto the electrodes\n\nMake sure to match the electrode label with the right head cap position.\n\n\nNIC2 will give you an indication of good connectivity and poor connectivity\n\n\nCodeplacement <- read_excel(\"electrode placement.xlsx\")\n\nplacement |> \n  hux() |> \n  theme_article()\n\n\n\n\n\n\nElectrode Placement\nChannel\n\n\nOZ (P7)\n1\n\n\nP4\n2\n\n\nCz\n3\n\n\nPz\n4\n\n\nP3\n5\n\n\nO1\n7\n\n\nO2\n8\n\n\nT8\n9\n\n\nF8\n10\n\n\nC4\n11\n\n\nF4\n12\n\n\nFp2\n13\n\n\nFz\n14\n\n\nC3\n15\n\n\nF3\n16\n\n\nFp1\n17\n\n\nT7\n18\n\n\nF7\n19\n\n\nFpz (EXT)\n20\n\n\n\n\nStep 5: Connect the ear clip\n\nOpen the ear clip by pressing the ends together\nPlace a drop of gel between the connector pads.\nConnect the reference cables to the ear clip.\nSecure the ear clip onto the participants right earlobe.\n\n[Take Picture]\nStep 6: Connect the device\n\nAttach the device to the large Velcro patch on the back of the head cap.\nConnect the electrode cables to the device.\n\n[Take Picture]\nMaintenance:\nStorage: The electrodes are supposed to be kept in the dark. When the actual electrode is exposed to light, it is damaged. The electrodes should be kept in an opaque box that will protect them from light and allow them to dry off when you’ve washed them after use.\n[Picture]\nCleaning: After you’ve finished with the experiment for the day, you must immediately clean the gel from the electrodes. Rise electrode with warm water, and gently remove the gel from the electrode entirely. This is harder than it looks - the gel has a tendency to dry up quickly in the tiny crevasses of the electrode. It may be beneficial to use a toothpick or a cotton swab to adequately remove all of the gel.\n[Picture] Consider getting waterflosser\nAfterwards, the electrodes should be placed in a dark box where they will allowed to dry.\nDocumentation: Every time you use the electrode, you must document the amount of time the electrode was used for. This keeps your electrodes on a replacement schedule. According to the manufacturer, Neuroelectrics, the electrodes only last for approximately 100 hours per electrode. If your experiment lasts 1 hour, you can think of this as if the electrode will be good for approximately 100 participants. Thus, in your lab notebook, document every use of the electrodes to be sure they are functioning properly during extended use.\n\nCodedata.frame(\n  Electrodes = placement$`Electrode Placement`,\n  Hours_Used = 80\n) |> \n  rename(`Hours Used` = Hours_Used) |> \n  hux() |> \n  theme_article()\n\n\n\n\n\n\nElectrodes\nHours Used\n\n\nOZ (P7)\n80\n\n\nP4\n80\n\n\nCz\n80\n\n\nPz\n80\n\n\nP3\n80\n\n\nO1\n80\n\n\nO2\n80\n\n\nT8\n80\n\n\nF8\n80\n\n\nC4\n80\n\n\nF4\n80\n\n\nFp2\n80\n\n\nFz\n80\n\n\nC3\n80\n\n\nF3\n80\n\n\nFp1\n80\n\n\nT7\n80\n\n\nF7\n80\n\n\nFpz (EXT)\n80\n\n\n\n\nOrdering Supplies: When you need to replace the electrodes or order more gel, you will need to complete work order requests and submit to Barbara. Use the below information in order to fast-track the process and give less work to Barbara!\nDetails for ordering Gel – include links, codes, and prices"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Hardware and Software Descriptions",
    "section": "",
    "text": "The Applied Psychology department recently acquired new software and hardware for use in research and academic settings.\nThis site aims to provide an overview of the equipment and software as well as proper use and care."
  },
  {
    "objectID": "index.html#hardware-eyetech-vt3-mini",
    "href": "index.html#hardware-eyetech-vt3-mini",
    "title": "Hardware and Software Descriptions",
    "section": "Hardware: EyeTech VT3 Mini",
    "text": "Hardware: EyeTech VT3 Mini\nThe EyeTech is a desktop mounted eye tracker. This device allows researchers to record data about where a participant looks, how long they are looking for, and other useful metrics for behavioral analyses."
  },
  {
    "objectID": "index.html#software-imotions",
    "href": "index.html#software-imotions",
    "title": "Hardware and Software Descriptions",
    "section": "Software: iMotions",
    "text": "Software: iMotions\niMotions acts as a bridge between the peripherals (eye tracker and EEG). It aims to consolidate everything into one window."
  },
  {
    "objectID": "index.html#hardware-neuroelectrics-enobio-20",
    "href": "index.html#hardware-neuroelectrics-enobio-20",
    "title": "Hardware and Software Descriptions",
    "section": "Hardware: Neuroelectrics Enobio 20",
    "text": "Hardware: Neuroelectrics Enobio 20\nThe Enobio 20 system is a portable and wearable EEG that allows researcher to collect data for brain research."
  },
  {
    "objectID": "index.html#software-nic2",
    "href": "index.html#software-nic2",
    "title": "Hardware and Software Descriptions",
    "section": "Software: NIC2",
    "text": "Software: NIC2\nNIC2 is a software that allows for the collection of EEG data."
  },
  {
    "objectID": "Experiment.html",
    "href": "Experiment.html",
    "title": "Creating an Experiment",
    "section": "",
    "text": "In iMotions click on the icon next to Library on the left hand of the screen.\n\n\n\nEnter the appropriate information into the specified fields.\n\nLeave the resolution and Display metrics as they are defaulted.\nChoose whether or not you want your stimuli to be randomized or follow the order that they are arranged in the navigator above (at this point the top of your screen should be blank).\nIf you wish to use blocks, make sure you check off Enable.\nUsing blocks will allow you to add specific randomization as well as looping, conditions, etc.\nA description is not necessary, but it can help.\n\n\n\n\n\nFig 1. Adding a new study in iMotions\n\n\nAll of the above customization occurs within the Study Settings tab.\nClick Next to progress to the next tab, Sensors.\n\nDepending on what data collection method you are looking for will change your selection.\n\nIf you are using Eyetracking make sure you check off the box.\nIf you are using the EEG, make sure you select Lab Streaming Layer."
  },
  {
    "objectID": "Experiment.html#adding-stimuli-ctrls",
    "href": "Experiment.html#adding-stimuli-ctrls",
    "title": "Creating an Experiment",
    "section": "Adding Stimuli (Ctrl+S)",
    "text": "Adding Stimuli (Ctrl+S)\n\nAt the top right of the screen you will see an icon, which when hovered over will allow you to add stimuli to your experiment.\n\nYou can use the following stimuli types:\n\nImage/Video\n\nThis option will most likely be the primary stimuli used in experiments. Most file formats are accepted.\n\nWeb Site\n\nThis option is useful if you wanted to see where participants look at certain websites. Advertisements, banners, pictures, etc.\n\nScreen Recording\n\nThis option is useful if your experiment is not based on a survey or cannot be created with iMotions built-in tools.\n\ne.g. Superlab/MATLAB/PsychoPy Experiments\n\n\nFace Recording\n\nThis option is useful if you are interested in viewing facial data.\nPost processing look at facial expressions, clues to explain odd data.\n\nScene Recording\n\nThis option is useful if you are using a USB camera to record interaction or data with something outside of your primary screen.\n\nSurvey Slide\n\nThis option is useful to create instructions, fixation crosses, and complete surveys.\n\nQualtrics Survey\n\nThis option is useful to incorporate a pre-existing Qualtircs survey with the ability to collect biometric data.\n\n\n\nFor the purpose of this walkthrough, we will be using Images/Video and Survey Slide.\n\nAdd an Instructions Survey Slide\n\n\nAll experiments should have an instructions slide. The purpose is to tell participants what they will be seeing in the experiment, as well as to create a buffer time before you start collecting the data.\n\nHaving a participant read a slide before collecting data might help in reducing any anxiety or stress experienced from being in an unfamiliar place.\n\nClick the Add Stimulus to Study button, or hit Ctrl+S.\nSelect Survey Slide\n\n\nDouble click Rich Text on the navigation menu to the left.\n\nEnter your instruction text.\n\n\nIn the following experiment, you will be shown several images. Before each image you will see a cross, please do your best to focus on the cross. When you are ready to begin, press SPACE.\n\n\nClick Save to Study at the bottom of the right of the screen.\nAdd another Survey Slide to your study.\nThis stimulus will act as a way for participants to type in what they saw and in what order they saw them.\n\nFrom the menu, select Text Response from the left navigation window.\nAdd a Rich Text object as well to tell your participants what they will be doing.\n\n\n\n\n\nAdd images to the study\n\nSelect Images/Video from the Add Stimulus to Study option.\nImport the images or videos you will be working with.\n\nFor our example, we will be using images of emotional scenes which can be downloaded here.\nSelect angry.png and press shift and click on sad.png to select all four images.\n\n\n\n\nGive your image(s) the appropriate name.\nIndicate the exposure time and description.\n\n\n\n\n\n\n\n\nNote\n\n\n\nNote: There is a lower limit to exposure that stops at 50ms.\n\n\n\nYou can also decide whether or not you want the slides to be advanced upon an input or limited to time frame.\n\nManual Advance: Require participant to submit a response before continuing\nExposure: This is helpful if you want to show an image for a specific duration of time\n\n\n\n\nMultiple Responses\nLet’s think about our experiment for a moment!\nWe want to show our participants an emotional image and then ask them what they say. We have four images, so we need to use four text responses!\n\n\nRight-click on text-response and click Clone.\n\nRepeat this step four times.\n\n\n\n\nOrganizing Stimuli in Block Editor\n\nAssuming that you have set your study settings to enable Stimuli Blocks, you will be able to access the Stimuli Batch Editor.\n\n\n\n\nHere you will see a preview of all of your stimuli, the name and exposure time. Additionally, you will see options for Manual Advance, Position Fixed, Track Mouse and Record Webcam.\nFor our purposes we would like to make it so that the experiment always begins with instructions, followed by our four images that will be randomized. The experiment will always finish with a response from the participant.\n\nSelect the Add New Block icon from the bottom bar.\n\nSelect each of your image stimuli and click on the right arrow to add them into the other window.\nSelect all four text-responses and place them beneath the emotional image\n\nEmotion > Text Response > Emotion > Text Response, etc.\n\nLabel this block “Randomize” and Save and Exit.\n\n\n\n\n\nAdd another block\nAdd your two survey slides into the right window and make sure to place the folder icon. “Randomize” in between them.\n\nMake sure to check the box that says Use Block as a runnable slideshow.\nLabel this block “Main Block” and Save and Exit.\n\n\n\n\nIt is always a good idea to make sure your block is appearing how you would like it to.\n\nSelect the third icon on the bottom row that says View Block\n\nIn this window you should see your nine items:\nInstructions > Four Emotional Faces > Four Text Responses\nYou should notice that Main Block stretches across the entire experiment and Randomize only stretches across the image stimuli.\nPress Shuffle a few times to make sure that the images are randomizing.\nClose the window to return to the editor and close that window as well.\n\n\n\n\nConsider Making a GIF of this!\n\n\nAdding a new User (Ctrl+D)\n\nSelect the icon on the right side of the screen next to where it says Respondents.\nEnter the appropriate information in the dialog boxes.\n\nFor testing purposes, you can put your own name in the box appended with “_test” so it can be deleted later on.\n\ne.g “Dave_Test”\n\nOtherwise, this field should contain only the participants SONA ID.\n\nLog the appropriate characteristics of Gender and Age.\nIf you plan to group your data by conditions, you can add a field in the Group dialog box.\nLeave the calibration mode as Regular.\n\n\n\n\nRunning the study\n\nYou are now ready to start collecting data for this study!\nMake sure to select your Respondent before you select Start Recording.\n\n\n\nIf you are using blocks in your experiment as we are in this sample one, it is helpful to select Auto select block to run in the Study Settings tab.\nMake sure that you are using the correct sensors\nOnce you click Start Recording you will be prompted with an informed consent window. This is a good reminder to make sure you obtain consent before any participant sits in the chair!\n\n\nOnce you have collected data, we will take a look at processing and analyzing the results!"
  },
  {
    "objectID": "Eyetracker.html",
    "href": "Eyetracker.html",
    "title": "Eyetracking",
    "section": "",
    "text": "iMotions is intended to be a two-part workstation. The participant will be seated at the leftmost computer and the experimenter will be seated at the rightmost computer. In order to do this you will have to make sure the computers are linked. Unless you make any changes, this will be the default configuration.\nThe device has already been preconfigured, so there is no need to change any of the settings inside of iMotions.\nIf connected, you will see a window on the bottom of the screen. When not looking into the view of the Eyetracker it will read Missing Eyes, when in view but not quite adjusted, the view will read Move closer. When the view is correct, the view will turn green.\n\n\nThere are two views that can be toggled from the eyetracker window. - One view shows you two white dots that are your eyeballs, if you right click and select toggle view you will see a horizontal bar - The other view shows an image of your eyes, you should see two different cross-hairs in the center of your eyes.\nIt is important that either or both of these views shows the participants eyes being captured properly.\n\n\n\n\n\n\nAssuming you have already followed the steps in the previous page, you just need to make sure a few options are set up:\n\nGo to your Study Settings and click on the Sensors tab.\n\nMake sure Eyetracker is enabled or checked-off.\n\n\n\n\n\nSelect your respondent and select Start Recording.\n\nThis will take your participant through a 9 point calibration.\n\nAssuming you have the dual station set up, you can see their progress in real-time.\n\n\nWhen finished, you will see a screen that tells you if the calibration was poor or good. (You should always aim for good!)\n\n\n\nIf the calibration is poor, you can retry or click on Verify which will show you the deviations from where the participants was meant to look, and where they actually looked.\n\nIt seems like eyeglasses do not always give the best results.\n\n\n\n\nSelect Continue to begin your experiment.\n\nMake sure to tell your participant to remain relatively still during the length of the experiment."
  },
  {
    "objectID": "Experiment.html#analyzing-data",
    "href": "Experiment.html#analyzing-data",
    "title": "Creating an Experiment",
    "section": "Analyzing Data",
    "text": "Analyzing Data\n\n\n\n\n\n\nNote\n\n\n\nNote: The study becomes locked once you have 1+ respondent. If you want to edit anything in the study, you will need to delete any test data.\n\n\nAfter you have collected data,right-click on your study name and select Add Analysis. You will see a screen with a series of steps referring to Segmentation. There are times when you might want to only analyze a certain age range, or a certain sex, or a certain condition.\nYou can name the analysis setting for future use as well.\n\n\nYou will then be able to configure Sensor Settings, that is–what you want to analyze in your data. In the Signal Processing section, click the + icon to add a new analysis option.\n\nSelect R Analysis GazeAnalysis I-VT Filter as the Device.\nSelect Raw Data Aggregationas the Algorithm\nChange the Flow Name as you see fit!\n\n\nNext, you will be able to select the stimuli that you want to include in the analysis.\n\nI deselected Instructions as that is not a stimulus I would envision getting much data from. Unless you were looking at attention or if you have some measure embedded in the instructions, I would suggest deselecting it.\nYou will then be shown an overview of analyses with the following options:\n\nReplay\nAggregate\nAOI’s\nHeatmap\nSignal Processing\nReports\nExport\n\n\nHere is an explanation for each section:\nReplay: This shows you a video of the respondent and the selected stimulus.\nAggregate: This will allow you to view different metrics across multiple participants. This is useful if you want to get a general heatmap of how all participants gaze.\nAOI’s: This will allow you to create Areas of Interest as well as calculate metrics.\nHeatmap: This creates an aggregate density of where the participant was fixated during the study. Darker areas correspond to longer fixations.\nSignal Processing:\nReports:\nExport:"
  },
  {
    "objectID": "Experiment.html#heatmaps",
    "href": "Experiment.html#heatmaps",
    "title": "Creating an Experiment",
    "section": "Heatmaps",
    "text": "Heatmaps"
  }
]